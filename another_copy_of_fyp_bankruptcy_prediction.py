# -*- coding: utf-8 -*-
"""Another copy of FYP-Bankruptcy Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1N_GH2NXbV3RfaR26YIRP4wdZvXPp125l
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import math
import matplotlib.ticker as mticker
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.neural_network import MLPClassifier
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
import xgboost as xgb
from sklearn.model_selection import RandomizedSearchCV
from sklearn.model_selection import GridSearchCV
from sklearn.feature_selection import VarianceThreshold
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, auc, accuracy_score, precision_recall_curve
from imblearn.over_sampling import SMOTE
from sklearn.feature_selection import SelectFromModel
from sklearn.impute import SimpleImputer

from google.colab import drive
drive.mount('/content/drive')

"""## EDA and Preprocessing

Initial Inspection of our data
"""

df = pd.read_csv('/content/drive/MyDrive/FYP/Original data.csv')

# Check the first 5 rows of the data
df.head()

#Check the last 5 rows of the data
df.tail()

#overview of the dataset dimensions
df.shape

# Check column names and data types
df.info()

# Basic Statistics
df.describe()

#Missing values check
df.isnull().sum()

#Duplicate check
df.duplicated().sum()

# Inspection of the class distribution
df['Bankrupt?'].value_counts(normalize=True)

for col in df.columns:
    print(f"\n Normalized value counts for column: '{col}'")
    display(df[col].value_counts(normalize=True, dropna=False).to_frame('percentage'))

# Convert numeric columns with <= 10 unique values to object
for col in df.select_dtypes(include='number').columns:
    unique_vals = df[col].nunique(dropna=False)
    if unique_vals <= 10:
        df[col] = df[col].astype('object')

print("Column type counts:")
print(df.dtypes.value_counts())

df.columns = df.columns.str.strip()

# Get list of object columns
cat_columns = df.select_dtypes(include='object').columns.tolist()

# Loop through each categorical column
for col in cat_columns:
    counts = df[col].value_counts()

    # Set up the side-by-side plots
    fig, axes = plt.subplots(1, 2, figsize=(12, 5))

    # Bar Plot
    counts.plot(kind='bar', ax=axes[0], color='skyblue', edgecolor='black')
    axes[0].set_title(f'Bar Plot of {col}')
    axes[0].set_xlabel(col)
    axes[0].set_ylabel('Count')
    axes[0].tick_params(axis='x', rotation=45)
    axes[0].grid(axis='y', linestyle='--', alpha=0.7)

    # Pie Chart
    axes[1].pie(counts, labels=counts.index, autopct='%1.1f%%', startangle=140)
    axes[1].set_title(f'Pie Chart of {col}')
    axes[1].axis('equal')  # Make pie a circle

    # Adjust layout
    plt.tight_layout()
    plt.show()

# Drop useless columns
df = df.drop(['Liability-Assets Flag', 'Net Income Flag'], axis=1, errors='ignore')

# Get list of object columns
cat_columns = df.select_dtypes(include='object').columns.tolist()

# Loop through each categorical column
for col in cat_columns:
    counts = df[col].value_counts()

    # Set up the side-by-side plots
    fig, axes = plt.subplots(1, 2, figsize=(12, 5))

    # Bar Plot
    counts.plot(kind='bar', ax=axes[0], color='skyblue', edgecolor='black')
    axes[0].set_title(f'Bar Plot of {col}')
    axes[0].set_xlabel(col)
    axes[0].set_ylabel('Count')
    axes[0].tick_params(axis='x', rotation=45)
    axes[0].grid(axis='y', linestyle='--', alpha=0.7)

    # Pie Chart
    axes[1].pie(counts, labels=counts.index, autopct='%1.1f%%', startangle=140)
    axes[1].set_title(f'Pie Chart of {col}')
    axes[1].axis('equal')  # Make pie a circle

    # Adjust layout
    plt.tight_layout()
    plt.show()

"""# Start with numerical values"""

# Select numeric columns
num_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()

df[num_columns].describe()

df_normalized = df.copy()

# Select only numerical columns
num_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()

# Initialize the scaler
scaler = MinMaxScaler()

# Apply Min-Max normalization
df_normalized[num_columns] = scaler.fit_transform(df[num_columns])

print(df_normalized[num_columns].min())
print(df_normalized[num_columns].max())

"""show outlier in box plot"""

# Get number of numeric columns
num_cols = len(df_normalized.select_dtypes(include='number').columns)
cols_per_row = 4
num_rows = math.ceil(num_cols / cols_per_row)

# Create boxplots with dynamic layout
df_normalized.select_dtypes(include='number').plot(
    kind='box',
    subplots=True,
    layout=(num_rows, cols_per_row),
    figsize=(cols_per_row * 4, num_rows * 4),
    sharey=False
)

plt.suptitle('Outlier Visualization with Boxplots', fontsize=16)
plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Leave space for the title
plt.show()

"""handle outlier using std capping"""

threshold = 4
df_capped = df_normalized.copy()

for col in df_capped.select_dtypes(include='number').columns:
    mean = df_capped[col].mean()
    std = df_capped[col].std()
    upper = mean + threshold * std
    lower = mean - threshold * std

    df_capped[col] = df_capped[col].clip(lower=lower, upper=upper)

"""compares the data before and after"""

# List of numeric columns
numeric_cols = df_normalized.select_dtypes(include='number').columns

# Loop through each column and plot 'before' and 'after' side-by-side
for col in numeric_cols:
    fig, axes = plt.subplots(1, 2, figsize=(12, 5))

    # Before handling outliers
    df_normalized.boxplot(column=col, ax=axes[0])
    axes[0].set_title(f'{col} - Before Outlier Handling')

    # After handling outliers (standard deviation capping)
    df_capped.boxplot(column=col, ax=axes[1])
    axes[1].set_title(f'{col} - After Outlier Handling')

    plt.suptitle(f'Outlier Comparison for "{col}"', fontsize=16)
    plt.tight_layout()
    plt.show()

# Specify your columns of interest
columns_to_compare = [
    'Revenue Per Share (Yuan Â¥)', 'Net Value Growth Rate', 'Current Ratio', 'Quick Ratio',
    'Total debt/Total net worth', 'Accounts Receivable Turnover', 'Average Collection Days',
    'Revenue per person', 'Allocation rate per person', 'Quick Assets/Current Liability',
    'Fixed Assets to Assets', 'Total assets to GNP price'
]

# Loop through each specified column and plot side-by-side
for col in columns_to_compare:
    if col in df_normalized.columns and col in df_capped.columns:
        fig, axes = plt.subplots(1, 2, figsize=(12, 5))

        # Before handling outliers
        df_normalized.boxplot(column=col, ax=axes[0])
        axes[0].set_title(f'{col} - Before Outlier Handling')

        # After handling outliers (standard deviation capping)
        df_capped.boxplot(column=col, ax=axes[1])
        axes[1].set_title(f'{col} - After Outlier Handling')

        plt.suptitle(f'Outlier Comparison for "{col}"', fontsize=16)
        plt.tight_layout()
        plt.show()
    else:
        print(f"Warning: Column '{col}' not found in one or both DataFrames.")

df_capped.shape

# Compute correlation matrix on cleaned data
corr_matrix = df_capped.corr().abs()

# Plot the heatmap
plt.figure(figsize=(60, 45))
sns.heatmap(
    corr_matrix,
    annot=True,
    fmt=".2f",
    cmap="coolwarm",
    linewidths=0.5,
    annot_kws={"size": 10},
    cbar_kws={'label': 'Correlation Coefficient'}
)

# Adjust axis labels and font size
plt.xticks(rotation=45, ha="right", fontsize=10)
plt.yticks(rotation=0, fontsize=10)

# Display the plot
plt.tight_layout()
plt.show()

target_col = 'Bankrupt?'

# Calculate correlation of each feature with the target (absolute value)
corr_with_target = df_capped.corr()[target_col].abs().sort_values(ascending=False)

# Get top 10 features most correlated with target (excluding the target itself)
top_10_features = corr_with_target[1:11].index.tolist()

print("Top 10 features most correlated with target:")
print(top_10_features)

sns.barplot(x=corr_with_target[top_10_features], y=top_10_features, palette="viridis")
plt.title("Top 10 Features Most Correlated with Bankruptcy")
plt.xlabel("Absolute Correlation")
plt.ylabel("Feature")
plt.tight_layout()
plt.show()

# Plotting the correlated features in a heatmap (after removing outliers)
corr_matrix = df_capped[top_10_features].corr().abs()
plt.figure(figsize=(12, 10))
sns.heatmap(
    corr_matrix,
    annot=True,
    fmt=".2f",
    cmap="coolwarm",
    linewidths=0.5,
    annot_kws={"size": 10},
    cbar_kws={'label': 'Correlation Coefficient'}
)
plt.xticks(rotation=45, ha="right", fontsize=10)
plt.yticks(fontsize=10)
plt.title("Correlation Heatmap of Top 10 Features (No Outliers)", fontsize=14)
plt.tight_layout()
plt.show()

# Function to find highly correlated feature pairs
def find_highly_correlated(corr_matrix, threshold=0.9):
    correlated_pairs = []
    for i in range(len(corr_matrix.columns)):
        for j in range(i):
            if abs(corr_matrix.iloc[i, j]) > threshold:
                correlated_pairs.append((corr_matrix.columns[i], corr_matrix.columns[j], corr_matrix.iloc[i, j]))
    return correlated_pairs

# Apply the function to detect highly correlated pairs
high_corr_pairs = find_highly_correlated(corr_matrix, threshold=0.9)

# Display the results
print("\nðŸ”— Highly Correlated Feature Pairs (>|0.9|):\n")
for f1, f2, corr_value in high_corr_pairs:
    print(f"- {f1} and {f2}: Correlation = {corr_value:.2f}")

def find_highly_correlated(corr_matrix, threshold=0.9):
    correlated_pairs = []
    cols = corr_matrix.columns
    for i in range(len(cols)):
        for j in range(i):
            corr_val = corr_matrix.iloc[i, j]
            if pd.notna(corr_val) and abs(corr_val) > threshold:
                correlated_pairs.append((cols[i], cols[j], corr_val))
    return correlated_pairs

def drop_correlated_features(df_clean, features, target_col='Bankrupt?', corr_threshold=0.9):
    # Compute correlation matrix for features only
    corr_matrix = df_clean[features].corr().abs()
    correlated_pairs = find_highly_correlated(corr_matrix, threshold=corr_threshold)

    to_drop = set()

    for f1, f2, corr_value in correlated_pairs:
        # Compute correlation with target, drop NaNs
        corr_with_target_f1 = abs(df_clean[[f1, target_col]].dropna().corr().iloc[0, 1])
        corr_with_target_f2 = abs(df_clean[[f2, target_col]].dropna().corr().iloc[0, 1])

        # Drop the feature with lower correlation with target
        if corr_with_target_f1 > corr_with_target_f2:
            to_drop.add(f2)
        else:
            to_drop.add(f1)

    cleaned_features = [f for f in features if f not in to_drop]

    print(f"\nDropped features due to high correlation: {list(to_drop)}")
    print(f"Remaining features after cleaning: {cleaned_features}")

    return cleaned_features

# Example usage:
# Make sure 'top_10_features' is a list of feature names you want to check
final_features = drop_correlated_features(df_capped, top_10_features, target_col='Bankrupt?', corr_threshold=0.9)

print("\nFinal Selected Features (after correlation cleaning):")
print(final_features)

df_capped.shape

df_capped[final_features].shape

cols_to_drop = [
    'Net worth/Assets',
    'ROA(A) before interest and % after tax',
    'ROA(B) before interest and depreciation after tax',
    'ROA(C) before interest and depreciation before interest'
]

# Create a new DataFrame with selected columns dropped
df_final = df_capped.drop(columns=cols_to_drop, errors='ignore')

print("Shape before:", df_capped.shape)
print("Shape after dropping columns:", df_final.shape)

# Step 1: Standardize the data
X = df_final.select_dtypes(include=['int64', 'float64'])
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Step 2: Apply PCA
pca = PCA(n_components=0.95)  # retain 95% of variance
X_pca = pca.fit_transform(X_scaled)

# Step 3: Check how many components were selected
print(f"Original features: {X.shape[1]}")
print(f"PCA selected components: {X_pca.shape[1]}")

# Optional: Create a DataFrame from the PCA results
pca_df = pd.DataFrame(X_pca, columns=[f'PC{i+1}' for i in range(X_pca.shape[1])])

# Fit PCA with all components for visualization
pca_full = PCA().fit(X_scaled)

plt.figure(figsize=(10, 6))
plt.plot(np.cumsum(pca_full.explained_variance_ratio_), marker='o', linestyle='--')
plt.xlabel('Number of Components')
plt.ylabel('Cumulative Explained Variance')
plt.title('Explained Variance by PCA Components')
plt.grid(True)
plt.axhline(y=0.95, color='red', linestyle='--', label='95% Variance')
plt.legend()
plt.show()

"""## Modeling with PCA parameters


```
# This is formatted as code
```

Random Forest
"""

# Define X (features from PCA) and y (target from original df_final)
X = pca_df
# Ensure y is an integer type for classification
y = df_final['Bankrupt?'].astype(int) # Explicitly convert to integer

# Split data
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

# Train on SMOTE-balanced data
model = RandomForestClassifier(random_state=42)
model.fit(X_train_smote, y_train_smote)

# Predict
y_pred = model.predict(X_test)

# Evaluate
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

"""Logisric Regression"""

# 1. Initialize Logistic Regression with class_weight balanced
log_reg = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)

# 2. Fit on SMOTE-resampled training data
log_reg.fit(X_train_smote, y_train_smote)


# 3. Predict probabilities
y_proba = log_reg.predict_proba(X_test)[:, 1]

# 4. Apply custom threshold
custom_threshold = 0.5
y_pred_custom = (y_proba >= custom_threshold).astype(int)

# 5. Evaluate
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("ROC AUC Score:", roc_auc_score(y_test, y_proba))

"""XGboost"""

# 1. Calculate scale_pos_weight
# This helps XGBoost handle imbalanced classes better
scale_weight = (len(y_train_smote) - sum(y_train_smote)) / sum(y_train_smote)

# 2. Initialize the XGBoost classifier
xgb_model = XGBClassifier(
    objective='binary:logistic',
    scale_pos_weight=scale_weight,
    use_label_encoder=False,
    eval_metric='logloss',
    random_state=42
)

# 3. Train the model
xgb_model.fit(X_train_smote, y_train_smote)

# 4. Predict probabilities on original test set
y_proba_xgb = xgb_model.predict_proba(X_test)[:, 1]

# 5. Apply custom threshold
custom_threshold = 0.8
y_pred_xgb = (y_proba_xgb >= custom_threshold).astype(int)

# 6. Evaluate
print("Classification Report:\n", classification_report(y_test, y_pred_xgb))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_xgb))
print("ROC AUC Score:", roc_auc_score(y_test, y_proba_xgb))

"""SVM"""

# Train SVM model on SMOTE-balanced data
svm_model = SVC(class_weight='balanced', random_state=42)
svm_model.fit(X_train_smote, y_train_smote)

# Predict
y_pred = svm_model.predict(X_test)

# Evaluate
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

"""KNL"""

# Train KNN model on SMOTE-balanced data
knn_model = KNeighborsClassifier(n_neighbors=5)  # You can adjust the number of neighbors (k)
knn_model.fit(X_train_smote, y_train_smote)

# Predict
y_pred = knn_model.predict(X_test)

# Evaluate
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

"""Decison Tree"""

# Train Decision Tree model on SMOTE-balanced data
dt_model = DecisionTreeClassifier(random_state=42)
dt_model.fit(X_train_smote, y_train_smote)

# Predict
y_pred = dt_model.predict(X_test)

# Evaluate
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

"""ANN"""

# Train ANN (MLP) model on SMOTE-balanced data
ann_model = MLPClassifier(hidden_layer_sizes=(50, 50), max_iter=1000, random_state=42)
ann_model.fit(X_train_smote, y_train_smote)

# Predict
y_pred = ann_model.predict(X_test)

# Evaluate
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

"""Clustering"""

# Train K-Means clustering model
kmeans_model = KMeans(n_clusters=2, random_state=42)  # Assuming we are clustering into 2 clusters
kmeans_model.fit(X_train_smote)

# Predict clusters
y_pred = kmeans_model.predict(X_test)

# Since KMeans doesn't output class labels, you might want to compare clusters with actual labels
# Here we're comparing cluster labels (y_pred) with actual class labels (y_test)
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

"""Modeling With Heatmap left columns

Random Forest
"""

# Prepare data
X = df_capped[final_features]
y = df_capped['Bankrupt?'].astype(int)
# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# SMOTE to handle class imbalance
smote_2 = SMOTE(random_state=42)
X_train_smote_2, y_train_smote_2 = smote.fit_resample(X_train, y_train)

# Train Random Forest model on SMOTE-balanced data
rf_model = RandomForestClassifier(random_state=42, class_weight='balanced')
rf_model.fit(X_train_smote_2, y_train_smote_2)

# Predict
y_pred = rf_model.predict(X_test)

# Evaluate
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

"""XGbosst"""

# Train XGBoost model on SMOTE-balanced data
xgb_model = XGBClassifier(random_state=42)  # Adjust ratio as needed
xgb_model.fit(X_train_smote_2, y_train_smote_2)

# Predict
y_pred = xgb_model.predict(X_test)

# Evaluate
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

"""SVM"""

# Train SVM model on SMOTE-balanced data
svm_model = SVC(random_state=42, class_weight='balanced')
svm_model.fit(X_train_smote_2, y_train_smote_2)

# Predict
y_pred = svm_model.predict(X_test)

# Evaluate
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

"""Logistic Regression"""

# Train Logistic Regression model on SMOTE-balanced data
logreg_model = LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000)
logreg_model.fit(X_train_smote_2, y_train_smote_2)

# Predict
y_pred = logreg_model.predict(X_test)

# Evaluate
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

"""KNL"""

# Train KNN model on SMOTE-balanced data
knn_model = KNeighborsClassifier(n_neighbors=5)
knn_model.fit(X_train_smote_2, y_train_smote_2)

# Predict
y_pred = knn_model.predict(X_test)

# Evaluate
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

"""Decison Tree"""

# Train Decision Tree model on SMOTE-balanced data
dt_model = DecisionTreeClassifier(random_state=42)
dt_model.fit(X_train_smote_2, y_train_smote_2)

# Predict
y_pred = dt_model.predict(X_test)

# Evaluate
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

"""ANN"""

# Train ANN (MLP) model on SMOTE-balanced data
ann_model = MLPClassifier(hidden_layer_sizes=(50, 50), max_iter=1000, random_state=42)
ann_model.fit(X_train_smote_2, y_train_smote_2)

# Predict
y_pred = ann_model.predict(X_test)

# Evaluate
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

"""Clustering"""

# Train K-Means clustering model
kmeans_model = KMeans(n_clusters=2, random_state=42)
kmeans_model.fit(X_train_smote_2)

# Predict clusters
y_pred = kmeans_model.predict(X_test)

# Since KMeans doesn't output class labels, you might want to compare clusters with actual labels
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))